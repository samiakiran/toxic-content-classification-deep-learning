### Toxic Content Classififcation in Online Environment


Online hateful discourse is an infant issue in our cutting edge society which is developing at a consistent rate. Many people stop expressing themselves and give up on seeking different opinions because of the hate comments. Content moderation has become necessary to have a healthy online conversation. The purpose of this research is to identify the toxic content to help improve the online conversation. To tackle this problem, this study proposes & compared 3 deep learning based approaches LSTM, Bi-LSTM and Bi-LSTM+CNN. We utilized dataset sourced from Wikipedia talk page, the proposed method Bi-LSTM+CNN gives a better AUC score of 98.78.


# Instructions

1. There are three .ipynb files insise the code directory namely LSTM.ipynb, Bi-LSTM.ipynb, Bi-LSTM+CNN.ipynb. Y
2. You can either run it directly on Google Colab or download the Jupyter Notebook to run on your local PC.
2. The dataset is taken from Kaggle Competition [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)
